{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os.path\n",
    "import torch\n",
    "import spacy\n",
    "import en_core_web_sm\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "PATH_TO_PRETRAINED = '/home/vika/cqas_flask/external_pretrained_models/'\n",
    "MODEL_NAMES = ['bert_simple1.hdf5']\n",
    "\n",
    "def load(checkpoint_fn, gpu=-1):\n",
    "    if not os.path.isfile(PATH_TO_PRETRAINED + checkpoint_fn):\n",
    "        raise ValueError('Can''t find tagger in file \"%s\". Please, run the main script with non-empty \\\n",
    "                         \"--save-best-path\" param to create it.' % checkpoint_fn)\n",
    "    tagger = torch.load(PATH_TO_PRETRAINED + checkpoint_fn)\n",
    "    tagger.gpu = gpu\n",
    "\n",
    "    tagger.word_seq_indexer.gpu = gpu # hotfix\n",
    "    tagger.tag_seq_indexer.gpu = gpu # hotfix\n",
    "    if hasattr(tagger, 'char_embeddings_layer'):# very hot hotfix\n",
    "        tagger.char_embeddings_layer.char_seq_indexer.gpu = gpu # hotfix\n",
    "    tagger.self_ensure_gpu()\n",
    "    return tagger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bert_simple1.hdf5\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('/home/vika/targer')\n",
    "from src.factories.factory_tagger import TaggerFactory\n",
    "from src.layers import layer_context_word_embeddings_bert\n",
    "\n",
    "for MODEL_NAME in ['bert_simple1.hdf5']:\n",
    "    print (MODEL_NAME)\n",
    "    model = TaggerFactory.load(PATH_TO_PRETRAINED + MODEL_NAME, 2)\n",
    "    print (model.gpu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning:  apex was installed without --cpp_ext.  Falling back to Python flatten and unflatten.\n",
      "Warning:  apex was installed without --cuda_ext. Fused syncbn kernels will be unavailable.  Python fallbacks will be used instead.\n",
      "Warning:  apex was installed without --cuda_ext.  FusedAdam will be unavailable.\n",
      "Warning:  apex was installed without --cuda_ext.  FusedLayerNorm will be unavailable.\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.insert(0, \"/home/vika/cqas_flask/generation/pytorch-transformers/pytorch_transformers\")\n",
    "from text_gen_big import text_generator_for_out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/vika/cqas_flask/generation/pytorch-transformers/pytorch_transformers/models/gpt2-large-pytorch_model.bin\n",
      "Whats is better bread or pizza\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using sep_token, but it is not set yet.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================== SAMPLE 1 ========================================\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"? This is a question we are asked a lot. It's one of those questions you have to think about if you want to keep your sanity. One of the common choices is pizza because it's easy to make and it's usually good. However, if you're like me and you're trying to be healthy, you want to go for something that is healthier and more nutrient dense, especially if it's a pizza. Bread is good for you, but it's not as nutritious as a pizza. This is true for the two main reasons.\\n\\nFirst, bread has a lot of carbohydrates. This means you need to eat a lot of it to get the same amount of energy as you get from a pizza. So it's not a good choice for a healthy diet. It's not even a good choice for a good eating plan because you need to eat lots of bread to get the same amount of energy as you get from a pizza. Secondly, bread is basically a high-fat\""
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_generator_for_out(\"Whats is better bread or pizza\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:523: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/user/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:524: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/user/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/user/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/user/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/user/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:532: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "from my_functions import do_sum, answerer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['whats', 'is', 'better', 'bread', 'or', 'pizza']]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.6/site-packages/torch/serialization.py:493: SourceChangeWarning: source code of class 'src.layers.layer_context_word_embeddings_bert.LayerContextWordEmbeddingsBert' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
      "  warnings.warn(msg, SourceChangeWarning)\n",
      "/home/user/.local/lib/python3.6/site-packages/torch/serialization.py:493: SourceChangeWarning: source code of class 'torch.nn.modules.sparse.Embedding' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
      "  warnings.warn(msg, SourceChangeWarning)\n",
      "/home/user/.local/lib/python3.6/site-packages/torch/serialization.py:493: SourceChangeWarning: source code of class 'torch.nn.modules.dropout.Dropout' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
      "  warnings.warn(msg, SourceChangeWarning)\n",
      "/home/user/.local/lib/python3.6/site-packages/torch/serialization.py:493: SourceChangeWarning: source code of class 'torch.nn.modules.linear.Linear' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
      "  warnings.warn(msg, SourceChangeWarning)\n",
      "/home/user/.local/lib/python3.6/site-packages/torch/serialization.py:493: SourceChangeWarning: source code of class 'torch.nn.modules.activation.Tanh' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
      "  warnings.warn(msg, SourceChangeWarning)\n",
      "/home/user/.local/lib/python3.6/site-packages/torch/serialization.py:493: SourceChangeWarning: source code of class 'torch.nn.modules.rnn.LSTM' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
      "  warnings.warn(msg, SourceChangeWarning)\n",
      "/home/user/.local/lib/python3.6/site-packages/torch/serialization.py:493: SourceChangeWarning: source code of class 'torch.nn.modules.activation.LogSoftmax' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
      "  warnings.warn(msg, SourceChangeWarning)\n",
      "/home/user/.local/lib/python3.6/site-packages/torch/serialization.py:493: SourceChangeWarning: source code of class 'torch.nn.modules.loss.NLLLoss' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
      "  warnings.warn(msg, SourceChangeWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-2\n",
      "[['O', 'O', 'B-PREDFULL', 'B-OBJ', 'O', 'O']]\n",
      "['bread']\n",
      "['better']\n",
      "We try to use spacy\n",
      "split_sent ['whats', 'is', 'better', 'bread', 'or', 'pizza']\n",
      "tokens  ['What', 's', 'is', 'better', 'bread', 'or', 'pizza']\n",
      "or simple split_sent 5\n",
      "bread pizza\n",
      "len(obj1), len(obj2) 5 5\n",
      "obj1, obj2, predicates bread pizza ['better']\n",
      "aspects ['better']\n",
      "weights [1]\n",
      "get url\n",
      "1\n",
      "create fro json predicates ['better']\n",
      "create fro json self.predicates better\n",
      "aspects  ['faster', 'easier to make', 'lighter', 'bigger'] ['safer', 'bit', 'cycle', 'production']\n",
      "2\n",
      "winnder: pizza  other: bread\n",
      "acpect winner  faster, easier to make, lighter, bigger\n",
      "acpect other  safer, bit, cycle, production\n",
      "self predicate  better\n",
      "answer begin:  The pizza is better than bread.\n",
      "/home/vika/cqas_flask/generation/pytorch-transformers/pytorch_transformers/models/gpt2-large-pytorch_model.bin\n",
      "The pizza is better than bread.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using sep_token, but it is not set yet.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================== SAMPLE 1 ========================================\n",
      "answer end str:   The pizza is better than food.\n",
      "\n",
      "I would like to take this opportunity to thank you for your support of me and my work. We really appreciate all the support you have given us so far.\n",
      "\n",
      "I hope you are enjoying your pizza.\n",
      "\n",
      "The pizza is better than bread.\n",
      "\n",
      "The pizza is better than food.\n",
      "\n",
      "I would like to take this opportunity to thank you for your support of me and my work. We really appreciate all the support you have given us so far.\n",
      "\n",
      "I hope you are enjoying your pizza.\n",
      "\n",
      "The pizza is better than bread.\n",
      "\n",
      "The pizza is better than food.\n",
      "\n",
      "I would like to take this opportunity to thank you for your support of me and my work. We really appreciate all the support you have given us so far.\n",
      "\n",
      "I hope you are enjoying your pizza.\n",
      "\n",
      "The pizza is better than bread.\n",
      "\n",
      "The pizza is better than food.\n",
      "\n",
      "I would like to take\n",
      "answer end str:   The pizza is better than food.I would like to take this opportunity to thank you for your support of me and my work. We really appreciate all the support you have given us so far.I hope you are enjoying your pizza.The pizza is better than bread.\n",
      "full answer  The pizza is better than bread.The reason is faster, easier to make, lighter, bigger. The pizza is better than food.I would like to take this opportunity to thank you for your support of me and my work. We really appreciate all the support you have given us so far.I hope you are enjoying your pizza.The pizza is better than bread.\n",
      "answer The pizza is better than bread.The reason is faster, easier to make, lighter, bigger. The pizza is better than food.I would like to take this opportunity to thank you for your support of me and my work. We really appreciate all the support you have given us so far.I hope you are enjoying your pizza.The pizza is better than bread.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'The pizza is better than bread.The reason is faster, easier to make, lighter, bigger. The pizza is better than food.I would like to take this opportunity to thank you for your support of me and my work. We really appreciate all the support you have given us so far.I hope you are enjoying your pizza.The pizza is better than bread.'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answerer(\"Whats is better bread or pizza\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = list(model.birnn_layer.parameters()) + list(model.lin_layer.parameters()) + list(model.log_softmax_layer.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TaggerBiRNN(\n",
       "  (word_embeddings_layer): LayerContextWordEmbeddingsBert(\n",
       "    (embeddings): BertModel(\n",
       "      (embeddings): BertEmbeddings(\n",
       "        (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "        (position_embeddings): Embedding(512, 768)\n",
       "        (token_type_embeddings): Embedding(2, 768)\n",
       "        (LayerNorm): BertLayerNorm()\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (encoder): BertEncoder(\n",
       "        (layer): ModuleList(\n",
       "          (0): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): BertLayerNorm()\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (1): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): BertLayerNorm()\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (2): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): BertLayerNorm()\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (3): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): BertLayerNorm()\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (4): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): BertLayerNorm()\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (5): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): BertLayerNorm()\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (6): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): BertLayerNorm()\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (7): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): BertLayerNorm()\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (8): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): BertLayerNorm()\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (9): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): BertLayerNorm()\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (10): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): BertLayerNorm()\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (11): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): BertLayerNorm()\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (pooler): BertPooler(\n",
       "        (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (activation): Tanh()\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.5, inplace=False)\n",
       "  (birnn_layer): LayerBiLSTM(\n",
       "    (rnn): LSTM(768, 200, batch_first=True, bidirectional=True)\n",
       "  )\n",
       "  (lin_layer): Linear(in_features=400, out_features=7, bias=True)\n",
       "  (log_softmax_layer): LogSoftmax()\n",
       "  (nll_loss): NLLLoss()\n",
       ")"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([30522, 768])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([30522, 768])\n",
      "torch.Size([512, 768])\n",
      "torch.Size([2, 768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768, 768])\n",
      "torch.Size([768])\n",
      "torch.Size([768, 768])\n",
      "torch.Size([768])\n",
      "torch.Size([768, 768])\n",
      "torch.Size([768])\n",
      "torch.Size([768, 768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n"
     ]
    }
   ],
   "source": [
    "for kv in a[:14]:\n",
    "    print (kv.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([30522, 768])\n",
      "torch.Size([512, 768])\n",
      "torch.Size([2, 768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768, 768])\n",
      "torch.Size([768])\n",
      "torch.Size([768, 768])\n",
      "torch.Size([768])\n",
      "torch.Size([768, 768])\n",
      "torch.Size([768])\n",
      "torch.Size([768, 768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n"
     ]
    }
   ],
   "source": [
    "for kv in b[:14]:\n",
    "    print (kv.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-57-ee8c2ab6104b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meq\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m215\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m215\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "torch.eq(b[215], a[215]).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([512, 768])"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "a_new = []\n",
    "for elem in a:\n",
    "    if len(elem.shape) > 1:\n",
    "        a_new.append(elem.view((elem.shape[1], elem.shape[0])))\n",
    "    else:\n",
    "        a_new.append(elem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([30522, 768])\n",
      "torch.Size([768, 30522])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "bool value of Tensor with more than one value is ambiguous",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-73-58bf1456f8cc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mkv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mkv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mkv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0ma_new\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m         \u001b[0mc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: bool value of Tensor with more than one value is ambiguous"
     ]
    }
   ],
   "source": [
    "c = []\n",
    "for ind, kv in enumerate(b):\n",
    "    print (kv.shape)\n",
    "    print (kv.view((kv.shape[1], kv.shape[0])).shape)\n",
    "    if (kv.view((kv.shape[1], kv.shape[0])) not in a_new):\n",
    "        c.append(kv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_sequence_from_sentence(str_sentences):\n",
    "    return [str_sentence.lower().split() for str_sentence in str_sentences]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = create_sequence_from_sentence(['what is better amazon or itunes', 'who is better mouse or rat', 'what is easier to make bread or pizza', 'what is better for startap python or mathlab', 'what is better memory foam or gel memory foam', 'what is better perl or python', 'what is better cuda or opencl', 'what is better gamecube or ps2', 'what is preferable beer or milk'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/home/vika/NER_RNN/targer')\n",
    "from src.factories.factory_tagger import TaggerFactory\n",
    "\n",
    "def create_sequence_from_sentence(str_sentences):\n",
    "    return [str_sentence.lower().split() for str_sentence in str_sentences]\n",
    "\n",
    "class extractor:\n",
    "    def __init__(self, input_sentence, model_name = 'bert_simple1.hdf5', model_path = '/home/vika/cqas_flask/external_pretrained_models/'):\n",
    "        self.input_str = input_sentence\n",
    "        self.answ = \"UNKNOWN ERROR\"\n",
    "        self.model_name = model_name\n",
    "        self.model_path = model_path\n",
    "        self.first_object = ''\n",
    "        self.second_object = ''\n",
    "        self.predicates = ''\n",
    "        \n",
    "    def get_objects_predicates(self, list_words, list_tags):\n",
    "        obj_list = []\n",
    "        pred_list = []\n",
    "        for ind, elem in enumerate(list_tags):\n",
    "            if elem == 'B-OBJ':\n",
    "                obj_list.append(list_words[ind])\n",
    "            if elem == 'B-PREDFULL':\n",
    "                pred_list.append(list_words[ind])    \n",
    "        return obj_list, pred_list\n",
    "    \n",
    "    def extract_objects_predicates(self, input_sentence):\n",
    "        words = create_sequence_from_sentence([input_sentence])\n",
    "        print (words)\n",
    "        model = TaggerFactory.load(self.model_path + self.model_name, -1)\n",
    "        print (model.gpu)\n",
    "        #model.cuda(device=2)\n",
    "        #model.gpu = 2\n",
    "        tags = model.predict_tags_from_words(words)\n",
    "        print (tags)\n",
    "        objects, predicates = self.get_objects_predicates(words[0], tags[0])\n",
    "        print (objects)\n",
    "        print (predicates)\n",
    "        self.predicates = predicates\n",
    "        if len(objects) >= 2:\n",
    "            self.first_object = objects[0]\n",
    "            self.second_object = objects[1]\n",
    "        else: # try to use spacy\n",
    "            \n",
    "            print(\"We try to use spacy\")\n",
    "            doc = nlp(input_sentence)\n",
    "            tokens = [token.text for token in doc]\n",
    "            split_sent = words[0]\n",
    "            if 'or' in split_sent:\n",
    "                comp_elem = 'or'\n",
    "            elif 'vs' in split_sent:\n",
    "                comp_elem = 'vs'\n",
    "            elif 'vs.' in split_sent:\n",
    "                comp_elem = 'vs.'\n",
    "            else:\n",
    "                self.answ = \"We can't recognize two objects for compare\"  \n",
    "                return;\n",
    "    \n",
    "            if (comp_elem in tokens):\n",
    "                or_index = tokens.index(comp_elem)\n",
    "                if (len (doc.ents) >= 2):\n",
    "                    for ent in doc.ents:\n",
    "                        print (\"or index doc snet\", or_index)\n",
    "                        print (\"begin end \", ent.start, ent.end, ent.text)\n",
    "                        if (ent.end == or_index):\n",
    "                            print (\"obj1 spacy doc sent\", ent.text)\n",
    "                            self.first_object = ent.text\n",
    "                        if (ent.start == or_index + 1):\n",
    "                            print (\"obj2 spacy doc sent\", ent.text)\n",
    "                            self.second_object = ent.text\n",
    "\n",
    "                else:\n",
    "                    print (\"or simple split_sent\", or_index)\n",
    "                    try:\n",
    "                        obj1 = split_sent[or_index - 1]\n",
    "                        obj2 = split_sent[or_index + 1]\n",
    "                        print (obj1, obj2)\n",
    "                        self.first_object = obj1\n",
    "                        self.second_object = obj2\n",
    "                    except:\n",
    "                        self.answ = \"We can't recognize two objects for compare\" \n",
    "\n",
    "            else:\n",
    "                self.answ = \"We can't recognize two objects for compare\" \n",
    "                \n",
    "    def get_params(self):\n",
    "        self.extract_objects_predicates(self.input_str)\n",
    "        return self.first_object.strip(\".,!/?\"), self.second_object.strip(\".,!/?\"), self.predicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['what', 'is', 'better', 'moscow', 'or', 'london?']]\n",
      "-2\n",
      "[['O', 'O', 'B-PREDFULL', 'O', 'O', 'O']]\n",
      "[]\n",
      "['better']\n",
      "We try to use spacy\n",
      "or index doc snet 4\n",
      "begin end  3 4 Moscow\n",
      "obj1 spacy doc sent Moscow\n",
      "or index doc snet 4\n",
      "begin end  5 6 London\n",
      "obj2 spacy doc sent London\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('Moscow', 'London', ['better'])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_extractor = extractor(\"What is better Moscow or London?\")\n",
    "my_extractor.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import requests\n",
    "import os.path\n",
    "import torch\n",
    "import spacy\n",
    "import en_core_web_sm\n",
    "\n",
    "URL = 'http://ltdemos.informatik.uni-hamburg.de/cam-api'\n",
    "\n",
    "proxies = {\n",
    "  \"http\": \"http://185.46.212.97:10015/\",\n",
    "  \"https\": \"https://185.46.212.98:10015/\",\n",
    "}\n",
    "\n",
    "def get_response(first_object, second_object, fast_search=True, \n",
    "               aspects=None, weights=None):\n",
    "    num_aspects = len(aspects) if aspects is not None else 0\n",
    "    num_weights = len(weights) if weights is not None else 0\n",
    "    if num_aspects != num_weights:\n",
    "        raise ValueError(\n",
    "            \"Number of weights should be equal to the number of aspects\")\n",
    "    params = {\n",
    "        'objectA': first_object,\n",
    "        'objectB': second_object,\n",
    "        'fs': str(fast_search).lower()\n",
    "    }\n",
    "    if num_aspects:\n",
    "        params.update({'aspect{}'.format(i + 1): aspect \n",
    "                       for i, aspect in enumerate(aspects)})\n",
    "        params.update({'weight{}'.format(i + 1): weight \n",
    "                       for i, weight in enumerate(weights)})\n",
    "    print (\"get url\")\n",
    "    response = requests.get(url=URL, params=params, proxies=proxies)\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class responser:\n",
    "    def __init__(self):\n",
    "        self.URL = 'http://ltdemos.informatik.uni-hamburg.de/cam-api'\n",
    "        self.proxies = {\"http\": \"http://185.46.212.97:10015/\",\"https\": \"https://185.46.212.98:10015/\",}\n",
    "        \n",
    "    def get_response(self, first_object, second_object, fast_search=True, \n",
    "               aspects=None, weights=None):\n",
    "        print (\"aspects\", aspects)\n",
    "        print (\"weights\", weights)\n",
    "        num_aspects = len(aspects) if aspects is not None else 0\n",
    "        num_weights = len(weights) if weights is not None else 0\n",
    "        if num_aspects != num_weights:\n",
    "            raise ValueError(\n",
    "                \"Number of weights should be equal to the number of aspects\")\n",
    "        params = {\n",
    "            'objectA': first_object,\n",
    "            'objectB': second_object,\n",
    "            'fs': str(fast_search).lower()\n",
    "        }\n",
    "        if num_aspects:\n",
    "            params.update({'aspect{}'.format(i + 1): aspect \n",
    "                           for i, aspect in enumerate(aspects)})\n",
    "            params.update({'weight{}'.format(i + 1): weight \n",
    "                           for i, weight in enumerate(weights)})\n",
    "        print (\"get url\", params)\n",
    "        response = requests.get(url=URL, params=params, proxies=proxies)\n",
    "        return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "URL = 'http://ltdemos.informatik.uni-hamburg.de/cam-api'\n",
    "proxies = {\"http\": \"http://185.46.212.97:10015/\",\"https\": \"https://185.46.212.98:10015/\",}\n",
    "params = {\n",
    "            'objectA': 'Moscow',\n",
    "            'objectB': 'London',\n",
    "            'fs': str(True).lower()}\n",
    "response = requests.get(url=URL, params=params, proxies=proxies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "f =response.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'extractedAspectsObject1': ['argument',\n",
       "  'power',\n",
       "  'authority',\n",
       "  'faster',\n",
       "  'fresher',\n",
       "  'smarter',\n",
       "  'easier',\n",
       "  'braver',\n",
       "  'better for the people of wales'],\n",
       " 'extractedAspectsObject2': ['greater', 'safer', 'bigger', 'quicker'],\n",
       " 'object1': {'name': 'moscow',\n",
       "  'points': {'none': 10.276372570011759},\n",
       "  'sentences': [{'CAM_score': 0.725490820169457,\n",
       "    'ES_score': 22.56571,\n",
       "    'confidence': 1,\n",
       "    'context_aspects': ['argument',\n",
       "     'power',\n",
       "     'authority',\n",
       "     'argument',\n",
       "     'power',\n",
       "     'authority'],\n",
       "    'id_pair': {'http://hitchensblog.mailonsunday.co.uk/2007/02/index.html': 664,\n",
       "     'http://hitchensblog.mailonsunday.co.uk/2007/02/other_peoples_c.html': 11},\n",
       "    'text': 'Though it was interesting that the state schools in Moscow were far better than their equivalents in London.'},\n",
       "   {'CAM_score': 0.69932320732406,\n",
       "    'ES_score': 21.751791,\n",
       "    'confidence': 1,\n",
       "    'context_aspects': [],\n",
       "    'id_pair': {'https://www.craigmurray.org.uk/archives/2012/07/martial-law-britain/': 334},\n",
       "    'text': 'In fact I came across a number of estates in London, particularly multi-apartment estates that are far worse than average Moscow estates.'},\n",
       "   {'CAM_score': 0.6548178919407949,\n",
       "    'ES_score': 20.367495,\n",
       "    'confidence': 1,\n",
       "    'context_aspects': ['fresher', 'smarter'],\n",
       "    'id_pair': {'http://www.smh.com.au/sport/athletics/towards-russia-with-dreams-20121207-2b1ph.html?skin=text-only': 7},\n",
       "    'text': 'Next year though he will tweak his preparation and arrive in Moscow for the world championships fresher and smarter than he did when he arrived in London an Olympic debutant.'},\n",
       "   {'CAM_score': 0.5996259973778343,\n",
       "    'ES_score': 18.650803,\n",
       "    'confidence': 1,\n",
       "    'context_aspects': ['easier'],\n",
       "    'id_pair': {'http://www.glutenfreemrsd.com/2011/06/': 3},\n",
       "    'text': 'When I graduated from University I moved to Moscow, Russia which was a lot easier and a whole heap more fun than getting a job in recession hit 90s London.'},\n",
       "   {'CAM_score': 0.594508466097352,\n",
       "    'ES_score': 18.491627,\n",
       "    'confidence': 1,\n",
       "    'context_aspects': ['faster'],\n",
       "    'id_pair': {'http://www.bloomberg.com/news/articles/2012-05-16/gazprom-at-discount-after-ny-oil-trails-london-russia-overnight': 3},\n",
       "    'text': \"OAO Gazprom and OAO Lukoil's U.S.- traded shares are fetching a discount to their Moscow stock for the first time in three years after oil tumbled faster in New York than in London.\"},\n",
       "   {'CAM_score': 0.5468930101086482,\n",
       "    'ES_score': 17.010593,\n",
       "    'confidence': 1,\n",
       "    'context_aspects': ['faster'],\n",
       "    'id_pair': {'http://www.theguardian.com/business/2008/may/01/automotive.russia1': 3},\n",
       "    'text': \"Once you've got the car you then have to negotiate the ubiquitous traffic jams in Moscow where cars move at a sedate average of 12mph - slightly faster than in London, which clocks in at a 11mph.\"},\n",
       "   {'CAM_score': 0.5445108130578451,\n",
       "    'ES_score': 16.936497,\n",
       "    'confidence': 1,\n",
       "    'context_aspects': [],\n",
       "    'id_pair': {\"http://www.theday.com/article/20140302/NWS14/303029922/1070/New-London-orders-biker-club-shut-down/Without-firing-shot-Putin's-troops-move-in-on-Ukrainian-peninsula\": 30},\n",
       "    'text': '\"Russia and the West find themselves on the brink of a confrontation far worse than in 2008 over Georgia,\" Dmitri Trenin, the director of Carnegie Moscow Center, said in a commentary posted on its website.'},\n",
       "   {'CAM_score': 0.5319529990618588,\n",
       "    'ES_score': 16.545898,\n",
       "    'confidence': 1,\n",
       "    'context_aspects': [],\n",
       "    'id_pair': {'http://en.chessbase.com/post/london-claic-carlsen-probably-the-best-che-player-in-the-world': 71},\n",
       "    'text': \"I don't want to tempt fate, and it is very wrong of me to make odious comparisons, but I can't resist: that's a much better percentage than the ten decisive games out of 45 played in Moscow recently.\"},\n",
       "   {'CAM_score': 0.5307218093072094,\n",
       "    'ES_score': 16.507603,\n",
       "    'confidence': 1,\n",
       "    'context_aspects': [],\n",
       "    'id_pair': {'http://yourfreedomandours.blogspot.co.uk/2010_03_01_archive.html': 55,\n",
       "     'http://yourfreedomandours.blogspot.com/2010/03/trying-to-understand-what-happened-in.html': 22},\n",
       "    'text': 'If that account of the immediate after-effects is correct and the pictures indicate that it might be, one can only say that Moscow seemed a good deal better organized and better prepared than London was back in 2005.'},\n",
       "   {'CAM_score': 0.5276398000775462,\n",
       "    'ES_score': 16.41174,\n",
       "    'confidence': 1,\n",
       "    'context_aspects': [],\n",
       "    'id_pair': {'http://issuu.com/tntmagazinelondon/docs/issue-1527?mode=window&backgroundColor=%23222222': 2556,\n",
       "     'http://www.tntdownunder.com/travel/world-travel/christmas-getaways-overseas-festive-holiday-ideas': 28,\n",
       "     'http://www.tntmagazine.com/travel/big-trip/christmas-getaways-overseas-festive-holiday-ideas': 28},\n",
       "    'text': 'Then take matters into your own hands and jet off to Moscow for the holidays where your chances of seeing snowflakes falling on December 25 are infinitely better than they are in London.'},\n",
       "   {'CAM_score': 0.5246421206749216,\n",
       "    'ES_score': 16.3185,\n",
       "    'confidence': 1,\n",
       "    'context_aspects': ['braver'],\n",
       "    'id_pair': {'http://www.theguardian.com/commentisfree/2014/mar/15/ukraine-crimea-sanctions-russian-investment-london': 34},\n",
       "    'text': 'Our legal profession was not bothered in the slightest that Magnitsky was a better and braver lawyer than they would or could ever be; a man who had died in a Moscow prison for the \"crime\" of exposing a gigantic tax fraud.'},\n",
       "   {'CAM_score': 0.5005132448947179,\n",
       "    'ES_score': 15.567994,\n",
       "    'confidence': 1,\n",
       "    'context_aspects': [],\n",
       "    'id_pair': {'http://www.irishtimes.com/sport/golf/mo-farah-strikes-gold-at-world-championships-1.1490740': 7,\n",
       "     'https://www.rte.ie/sport/athletics/2013/0810/467470-farah-strolls-to-10-000m-gold-medal/': 7},\n",
       "    'text': 'The 30-year-old had said ahead of Moscow he now has a target on his back every time he raced, but warned his rivals he was a better athlete this year than at London 2012.'},\n",
       "   {'CAM_score': 0.4837269153930387,\n",
       "    'ES_score': 15.045871,\n",
       "    'confidence': 1,\n",
       "    'context_aspects': ['better for the people of wales'],\n",
       "    'id_pair': {'http://ufdc.ufl.edu/UF00072012/00008': 825},\n",
       "    'text': 'The learned Solicitor General seemed to think that a judge in the neighbourhood was an evil, and he would probably think a judgment delivered at Moscow even better for the people of Wales than one delivered in London.'}],\n",
       "  'totalPoints': 10.276372570011759},\n",
       " 'object2': {'name': 'london',\n",
       "  'points': {'none': 10.888407301169043},\n",
       "  'sentences': [{'CAM_score': 1.0,\n",
       "    'ES_score': 31.10406,\n",
       "    'confidence': 1,\n",
       "    'context_aspects': [],\n",
       "    'id_pair': {'http://www.stlbeacon.org/?_escaped_fragment_=/content/14533/london_chess_classic_proves_better_than_moscow': 1},\n",
       "    'text': 'London Chess Classic proves better than Moscow .'},\n",
       "   {'CAM_score': 0.7026601350434637,\n",
       "    'ES_score': 21.855583,\n",
       "    'confidence': 1,\n",
       "    'context_aspects': ['greater', 'greater', 'greater'],\n",
       "    'id_pair': {'http://krwg.org/post/london-through-eyes-dickens-victorian-city': 6,\n",
       "     'http://www.npr.org/2014/07/22/331733079/london-through-the-eyes-of-dickens-in-the-victorian-city?ft=1': 5,\n",
       "     'http://www.wnyc.org/story/london-through-the-eyes-of-dickens-in-the-victorian-city/': 6},\n",
       "    'text': 'By 1911 that number had grown to a staggering 7 million: a population far greater than Paris, Berlin, St. Petersburg and Moscow combined at that time.'},\n",
       "   {'CAM_score': 0.6607804254492822,\n",
       "    'ES_score': 20.552954,\n",
       "    'confidence': 1,\n",
       "    'context_aspects': ['faster'],\n",
       "    'id_pair': {'http://www.bloomberg.com/news/print/2014-04-08/putin-s-call-to-moscow-ignored-as-russian-adrs-rally.html': 10},\n",
       "    'text': 'Since the incursion into the Black Sea peninsula on March 1, investors turned to offshore equity trading, with London volume growing faster than that of Moscow.'},\n",
       "   {'CAM_score': 0.6438071750118795,\n",
       "    'ES_score': 20.025017,\n",
       "    'confidence': 1,\n",
       "    'context_aspects': ['safer', 'safer'],\n",
       "    'id_pair': {'http://www.rferl.org/content/Czech_Mate_How_Russia_Is_Rebuilding_Influence_In_The_Former_Soviet_Bloc/2168090.html': 49,\n",
       "     'https://therearenosunglasses.wordpress.com/2010/09/26/': 52},\n",
       "    'text': \"To those Russians, Prague is a more affordable version of London: an urban asylum that's safer and more civilized than teeming, lawless Moscow, and a convenient few hours' flight away.\"},\n",
       "   {'CAM_score': 0.632845679953035,\n",
       "    'ES_score': 19.68407,\n",
       "    'confidence': 1,\n",
       "    'context_aspects': ['greater', 'greater', 'greater'],\n",
       "    'id_pair': {'http://blogs.barrons.com/emergingmarketsdaily/2013/09/02/emerging-markets-evening-roundup-emerging-markets-rally-after-china-data-south-africa-gold-miners-to-start-strike-tomorrow/': 12,\n",
       "     'http://blogs.barrons.com/emergingmarketsdaily/2013/09/02/emerging-markets-evening-roundup-emerging-markets-rally-after-china-data-south-africa-gold-miners-to-start-strike-tomorrow/tab/print/': 12,\n",
       "     'http://blogs.barrons.com/emergingmarketsdaily/search/GMO/?s=GMO': 120},\n",
       "    'text': 'The 30-day average value of trades in 10 of the biggest Russian companies tracked by Bloomberg in London is about 50 percent greater than in Moscow.'},\n",
       "   {'CAM_score': 0.6097553181160272,\n",
       "    'ES_score': 18.965866,\n",
       "    'confidence': 1,\n",
       "    'context_aspects': ['bigger'],\n",
       "    'id_pair': {'http://www.eurotrip.com/content/how-use-eurotripa-beginner039s-primer?page=1': 72},\n",
       "    'text': \"All right, it's a lot smaller than London (as many people live in Greater London as in all of Belgium) or Moscow, but I get the feeling you only saw a tiny little bit of it.\"},\n",
       "   {'CAM_score': 0.5977632823496354,\n",
       "    'ES_score': 18.592865,\n",
       "    'confidence': 1,\n",
       "    'context_aspects': ['safer', 'safer'],\n",
       "    'id_pair': {'http://www.haaretz.com/jewish/2.209/swiss-muslims-gain-support-from-unexpected-source-rabbis-1.2870': 17,\n",
       "     'http://www.haaretz.com/misc/article-print-page/swiss-muslims-gain-support-from-unexpected-source-rabbis-1.2870?trailingPath=2.169%2C2.208%2C2.209%2C': 18},\n",
       "    'text': 'Jonasan Abraham, a London rabbi, said it was \"tragic to think that it\\'s safer now to walk the streets of Moscow as a Jew than in many Western European capitals where you feel hostility\".'},\n",
       "   {'CAM_score': 0.5976839357948769,\n",
       "    'ES_score': 18.590397,\n",
       "    'confidence': 1,\n",
       "    'context_aspects': ['safer'],\n",
       "    'id_pair': {'http://gatesofvienna.blogspot.com/2009/12/gates-of-vienna-news-feed-1252009.html': 138},\n",
       "    'text': 'Jonasan Abraham, a London rabbi, said it was \"tragic to think that it\\'s safer now to walk the streets of Moscow as a Jew than in many Western European capitals where you feel hostility.\"'},\n",
       "   {'CAM_score': 0.5544010010268756,\n",
       "    'ES_score': 17.244122,\n",
       "    'confidence': 1,\n",
       "    'context_aspects': ['quicker'],\n",
       "    'id_pair': {'http://www.seat61.com/SilkRoute.htm': 48},\n",
       "    'text': 'On the return journey I travelled via Astana and as a result made the journey from Almaty to London in under 5 days, about 13 hours quicker than using the direct train from Almaty to Moscow (train 7/8).'},\n",
       "   {'CAM_score': 0.5003396662686479,\n",
       "    'ES_score': 15.562595,\n",
       "    'confidence': 1,\n",
       "    'context_aspects': [],\n",
       "    'id_pair': {'http://www.marketwired.com/press-release/early-hours-recap-on-auy-ngd-and-hmy-1758093.htm': 2},\n",
       "    'text': \"LONDON--(Marketwire - Feb 19, 2013) - Stocks ended on a mixed note on Friday's trading session as better-than-expected U.S. economic data was overshadowed by the G20 summit, which was held in Moscow over the weekend.\"},\n",
       "   {'CAM_score': 0.4757885948008073,\n",
       "    'ES_score': 14.798957,\n",
       "    'confidence': 1,\n",
       "    'context_aspects': [],\n",
       "    'id_pair': {'http://www.ibtimes.co.uk/oscar-pistoirus-endorese-lonodn-2017-world-athletic-411689': 23},\n",
       "    'text': 'While his experience from London will live with him until the end of his career, Pistorius is already focused on returning to the track in 2013 in better shape than ever; with the Moscow World Championships on the horizon.'}],\n",
       "  'totalPoints': 10.888407301169043},\n",
       " 'sentenceCount': 24,\n",
       " 'winner': 'london'}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 1., 1., 1., 1.])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.ones(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['what', 'is', 'better', 'moscow', 'or', 'london?']]\n",
      "-2\n",
      "[['O', 'O', 'B-PREDFULL', 'O', 'O', 'O']]\n",
      "[]\n",
      "['better']\n",
      "We try to use spacy\n",
      "or index doc snet 4\n",
      "begin end  3 4 Moscow\n",
      "obj1 spacy doc sent Moscow\n",
      "or index doc snet 4\n",
      "begin end  5 6 London\n",
      "obj2 spacy doc sent London\n",
      "Moscow London ['better']\n",
      "aspects ['better']\n",
      "weights [1]\n",
      "get url {'objectA': 'Moscow', 'objectB': 'London', 'fs': 'true', 'aspect1': 'better', 'weight1': 1}\n"
     ]
    }
   ],
   "source": [
    "my_responser = responser()\n",
    "obj1, obj2, predicates = my_extractor.get_params()\n",
    "print (obj1, obj2, predicates)\n",
    "if (len(obj1) > 0 and len(obj2) > 0):\n",
    "    response = my_responser.get_response(first_object = obj1, second_object = obj2, fast_search=True, aspects = predicates, weights = [1 for predicate in predicates])\n",
    "else:\n",
    "    print (\"smth wrong with objects obj1 %s obj2 %s\", obj1, obj2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = response.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def answerer(input_string):\n",
    "    my_extractor = extractor(input_string)\n",
    "    my_responser = responser()\n",
    "    obj1, obj2, predicates = my_extractor.get_params()\n",
    "    print (obj1, obj2, predicates)\n",
    "    if (len(obj1) > 0 and len(obj2) > 0):\n",
    "        response =  my_responser.get_response(first_object = obj1, second_object = obj2, fast_search=True, aspects = predicates, weights = [1 for predicate in predicates])\n",
    "        try:\n",
    "            response_json = response.json()\n",
    "            my_diviner = diviner()\n",
    "            my_diviner.create_from_json(response_json, predicates)\n",
    "            answer = my_diviner.generate_advice()\n",
    "            return answer\n",
    "        except:\n",
    "            return (\"smth wrong in response, please try again\")\n",
    "    else:\n",
    "        return (\"smth wrong with objects obj1 %s obj2 %s\", obj1, obj2)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['what', 'is', 'better', 'moscow', 'or', 'london?']]\n",
      "-2\n",
      "[['O', 'O', 'B-PREDFULL', 'O', 'O', 'O']]\n",
      "[]\n",
      "['better']\n",
      "We try to use spacy\n",
      "or index doc snet 4\n",
      "begin end  3 4 Moscow\n",
      "obj1 spacy doc sent Moscow\n",
      "or index doc snet 4\n",
      "begin end  5 6 London\n",
      "obj2 spacy doc sent London\n",
      "Moscow London ['better']\n",
      "aspects ['better']\n",
      "weights [1]\n",
      "get url {'objectA': 'Moscow', 'objectB': 'London', 'fs': 'true', 'aspect1': 'better', 'weight1': 1}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'smth wrong in response, please try again'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answerer(\"What is better Moscow or London?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, \"/home/vika/cqas_flask/generation/gpt-2-Pytorch\")\n",
    "from text_gen import text_generator_for_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▎         | 5/200 [00:00<00:04, 42.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The moscow is better than london\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:04<00:00, 42.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "qu\n",
      "======================================== SAMPLE 1 ========================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "answer_end = text_generator_for_out(\"The moscow is better than london\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['. You know the difference. It\\'s not like they\\'re trying to sell you something. It\\'s just that they\\'re looking for a way to make money off of it. It\\'s because they do it that they\\'re going to make money off of it.\"',\n",
       " '',\n",
       " \"I'm not going to lie. I'm not going to lie to you. I think it's amazing how much money they are making off of it.\",\n",
       " '',\n",
       " \"They do make money off of it. But it's not that they can't make money off of it. It's just that it's not that they know how to make money off of it.\",\n",
       " '',\n",
       " 'They make money off of it.',\n",
       " '',\n",
       " 'They make money off of it.',\n",
       " '',\n",
       " 'They make money off of it.',\n",
       " '',\n",
       " 'They make money off of it.',\n",
       " '',\n",
       " 'They make money off of it.',\n",
       " '',\n",
       " 'They make money off of it.',\n",
       " '',\n",
       " 'They make money off of it.',\n",
       " '',\n",
       " 'They make money off of it.']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answer_end.splitlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\".\\n\\n\\nI'll leave you with a link to the video where the muscow shows you how to make the moscow but without the mushroom, you need to cut off the ends of the mushroom and then the mushrooms.\\n\\nHere are some pics of the muscow,\\n\\n(click them to enlarge):\\n\\n\\nThe mushroom is a wonderful gift and the mushroom is very useful because you can grow it for a long time.\\n\\n\\nHere's my muscow that you can grow for a long time.\\n\\n\\nHere's a picture of my muscow.\\n\\n\\nNow, I'm going to show you how a muscow is made from the following:\\n\\nA muscow with a mushroom as its base.\\n\\nA muscow with a mushroom as its top.\\n\\nA muscow with a mushroom as its base.\\n\\nA muscow with a mushroom as its top.\\n\\nYou can choose between 3 different shapes for your muscow.\\n\\n\\nHere\""
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answer_end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.path.exists('/home/vika/cqas_flask/generation/gpt-2-Pytorch' + '/' + 'gpt2-pytorch_model.bin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\".\\n\\n\\nI'll leave you with a link to the video where the muscow shows you how to make the moscow but without the mushroom, you need to cut off the ends of the mushroom and then the mushrooms.\\n\\nHere are some pics of the muscow,\\n\\n(click them to enlarge):\\n\\n\\nThe mushroom is a wonderful gift and the mushroom is very useful because you can grow it for a long time.\\n\\n\\nHere's my muscow that you can grow for a long time.\\n\\n\\nHere's a picture of my muscow.\\n\\n\\nNow, I'm going to show you how a muscow is made from the following:\\n\\nA muscow with a mushroom as its base.\\n\\nA muscow with a mushroom as its top.\\n\\nA muscow with a mushroom as its base.\\n\\nA muscow with a mushroom as its top.\\n\\nYou can choose between 3 different shapes for your muscow.\\n\\n\\nHere\""
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answer_end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/vika/cqas_flask\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "print (os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "aspects  ['greater', 'safer', 'bigger', 'quicker'] ['argument', 'power', 'authority', 'faster']\n",
      "winnder: london  other: moscow\n",
      "acpect winner  greater, safer, bigger, quicker\n",
      "acpect other  argument, power, authority, faster\n",
      "self predicate  better\n",
      "answer begin  The london is better than moscow.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 4/200 [00:00<00:05, 38.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The london is better than moscow.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:04<00:00, 41.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "qu\n",
      "======================================== SAMPLE 1 ========================================\n",
      "answer end   https://t.co/0Wl4jqXVfZ — Ralf Bering (@Bering_Ralf) November 17, 2017\n",
      "\n",
      "The Daily Mail has confirmed the club's new owner, who is from Leeds, will take over the club from his former boss, Mark Hughes.\n",
      "\n",
      "In a statement, Ralf said: \"I feel like I can say this, although I don't think I've ever been the kind of person who would talk about my life in the media.\n",
      "\n",
      "\"I've never been an editor of a Sunday newspaper and I didn't ever have a real agenda. My job in the media was to get the news and to be the news.\n",
      "\n",
      "\"I have a very limited amount of time in the media so I have never been in a position to work on everything.\n",
      "\n",
      "\"My career has been going on for over 20 years now and I'm still a little bit of an outsider. I've also got\n",
      "full answer  The london is better than moscow.The reason is greater, safer, bigger, quicker https://t.co/0Wl4jqXVfZ — Ralf Bering (@Bering_Ralf) November 17, 2017\n",
      "\n",
      "The Daily Mail has confirmed the club's new owner, who is from Leeds, will take over the club from his former boss, Mark Hughes.\n",
      "\n",
      "In a statement, Ralf said: \"I feel like I can say this, although I don't think I've ever been the kind of person who would talk about my life in the media.\n",
      "\n",
      "\"I've never been an editor of a Sunday newspaper and I didn't ever have a real agenda. My job in the media was to get the news and to be the news.\n",
      "\n",
      "\"I have a very limited amount of time in the media so I have never been in a position to work on everything.\n",
      "\n",
      "\"My career has been going on for over 20 years now and I'm still a little bit of an outsider. I've also got\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'The london is better than moscow.The reason is greater, safer, bigger, quicker https://t.co/0Wl4jqXVfZ — Ralf Bering (@Bering_Ralf) November 17, 2017\\n\\nThe Daily Mail has confirmed the club\\'s new owner, who is from Leeds, will take over the club from his former boss, Mark Hughes.\\n\\nIn a statement, Ralf said: \"I feel like I can say this, although I don\\'t think I\\'ve ever been the kind of person who would talk about my life in the media.\\n\\n\"I\\'ve never been an editor of a Sunday newspaper and I didn\\'t ever have a real agenda. My job in the media was to get the news and to be the news.\\n\\n\"I have a very limited amount of time in the media so I have never been in a position to work on everything.\\n\\n\"My career has been going on for over 20 years now and I\\'m still a little bit of an outsider. I\\'ve also got'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import json\n",
    "import requests\n",
    "import os.path\n",
    "import torch\n",
    "import spacy\n",
    "import en_core_web_sm\n",
    "\n",
    "\n",
    "from generation.generation import diviner\n",
    "\n",
    "response_json = response.json()\n",
    "Merlin = diviner()\n",
    "Merlin.create_from_json(response_json, 'better')\n",
    "Merlin.generate_advice()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "winnder: london  other: moscow\n",
      "acpect winner  greater, safer, bigger, quicker\n",
      "acpect other  argument, power, authority, faster\n",
      "self predicate  better\n",
      "answer begin  The london is better than moscow.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 4/200 [00:00<00:05, 34.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The london is better than moscow.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:04<00:00, 40.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "qu\n",
      "======================================== SAMPLE 1 ========================================\n",
      "answer end  \n",
      "\n",
      "This is the most interesting thing about the london. It is not just a london but a city or a city and a city is the london. It is only when the london is a city that the city is a city. The london is the london where you don't have to be a city. Its the london where you do not need to be a city to be a london.\n",
      "\n",
      "The london is the london where you don't have to be a city to be a london. The london is where your friends are. Its the london where you don't have to be a city.\n",
      "\n",
      "The london is the london where you don't have to be a city to be a london. The london is where you don't have to be a city.\n",
      "\n",
      "The london is the london where you don't have to be a city to be a london. The london is\n",
      "full answer  The london is better than moscow.The reason is greater, safer, bigger, quicker\n",
      "\n",
      "This is the most interesting thing about the london. It is not just a london but a city or a city and a city is the london. It is only when the london is a city that the city is a city. The london is the london where you don't have to be a city. Its the london where you do not need to be a city to be a london.\n",
      "\n",
      "The london is the london where you don't have to be a city to be a london. The london is where your friends are. Its the london where you don't have to be a city.\n",
      "\n",
      "The london is the london where you don't have to be a city to be a london. The london is where you don't have to be a city.\n",
      "\n",
      "The london is the london where you don't have to be a city to be a london. The london is\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"The london is better than moscow.The reason is greater, safer, bigger, quicker\\n\\nThis is the most interesting thing about the london. It is not just a london but a city or a city and a city is the london. It is only when the london is a city that the city is a city. The london is the london where you don't have to be a city. Its the london where you do not need to be a city to be a london.\\n\\nThe london is the london where you don't have to be a city to be a london. The london is where your friends are. Its the london where you don't have to be a city.\\n\\nThe london is the london where you don't have to be a city to be a london. The london is where you don't have to be a city.\\n\\nThe london is the london where you don't have to be a city to be a london. The london is\""
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Merlin.generate_advice()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['what', 'is', 'better', 'tea', 'or', 'coffee?']]\n",
      "-2\n",
      "[['O', 'O', 'B-PREDFULL', 'B-OBJ', 'O', 'O']]\n",
      "['tea']\n",
      "['better']\n",
      "We try to use spacy\n",
      "or simple split_sent 4\n",
      "tea coffee?\n",
      "len(obj1), len(obj2) 3 6\n",
      "obj1, obj2, predicates tea coffee ['better']\n",
      "aspects ['better']\n",
      "weights [1]\n",
      "get url\n",
      "1\n",
      "aspects  ['better for you', 'easier', 'better for the environment', 'safer'] ['greater', 'easier to keep your weight under control with green tea as part of your diet', 'caffeine', 'cooler']\n",
      "2\n",
      "winnder: tea  other: coffee\n",
      "acpect winner  better for you, easier, better for the environment, safer\n",
      "acpect other  greater, easier to keep your weight under control with green tea as part of your diet, caffeine, cooler\n",
      "self predicate  better\n",
      "answer begin:  The tea is better than coffee.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▎         | 5/200 [00:00<00:04, 44.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The tea is better than coffee.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:04<00:00, 43.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "qu\n",
      "======================================== SAMPLE 1 ========================================\n",
      "qu2\n",
      "qu3\n",
      "answer end str:  \n",
      "\n",
      "For me, though, the best tea is not coffee but coffee in the form of a tea. If you want a tea that's truly delicious, then don't rely on a cup of tea as your main source of tea. The best coffee is always coffee.\n",
      "\n",
      "If you're thinking, \"Wow, maybe this is the best tea I've ever had!\" then you're not alone.\n",
      "\n",
      "The best tea is always coffee, especially if you're a tea drinker.\n",
      "\n",
      "This is how I think of my favorite coffee.\n",
      "\n",
      "I like to have a cup of tea with me every day. So how often do I get a cup of coffee?\n",
      "\n",
      "When I first started using the tea method as an alternative to coffee, it was quite simple.\n",
      "\n",
      "You get a cup of coffee daily, and then you get another cup each day.\n",
      "\n",
      "My friend and I used to go to the store to buy coffee.\n",
      "\n",
      "We were always on\n",
      "answer end str:  For me, though, the best tea is not coffee but coffee in the form of a tea. If you want a tea that's truly delicious, then don't rely on a cup of tea as your main source of tea. The best coffee is always coffee.If you're thinking, \"Wow, maybe this is the best tea I've ever had!\" then you're not alone.The best tea is always coffee, especially if you're a tea drinker.\n",
      "full answer  The tea is better than coffee.The reason is better for you, easier, better for the environment, safer.For me, though, the best tea is not coffee but coffee in the form of a tea. If you want a tea that's truly delicious, then don't rely on a cup of tea as your main source of tea. The best coffee is always coffee.If you're thinking, \"Wow, maybe this is the best tea I've ever had!\" then you're not alone.The best tea is always coffee, especially if you're a tea drinker.\n",
      "answer The tea is better than coffee.The reason is better for you, easier, better for the environment, safer.For me, though, the best tea is not coffee but coffee in the form of a tea. If you want a tea that's truly delicious, then don't rely on a cup of tea as your main source of tea. The best coffee is always coffee.If you're thinking, \"Wow, maybe this is the best tea I've ever had!\" then you're not alone.The best tea is always coffee, especially if you're a tea drinker.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'The tea is better than coffee.The reason is better for you, easier, better for the environment, safer.For me, though, the best tea is not coffee but coffee in the form of a tea. If you want a tea that\\'s truly delicious, then don\\'t rely on a cup of tea as your main source of tea. The best coffee is always coffee.If you\\'re thinking, \"Wow, maybe this is the best tea I\\'ve ever had!\" then you\\'re not alone.The best tea is always coffee, especially if you\\'re a tea drinker.'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "from my_functions import do_sum, answerer\n",
    "answerer(\"what is better tea or coffee?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "super(type, obj): obj must be an instance or subtype of type",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-311a4e67ee93>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtext_gen\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtext_generator_for_out\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtext_generator_for_out\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"The pizza is better than bread.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/home/vika/cqas_flask/generation/gpt-2-Pytorch/text_gen.py\u001b[0m in \u001b[0;36mtext_generator_for_out\u001b[0;34m(text, length, temperature, top_k, path_to_model)\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0menc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_encoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m         \u001b[0mconfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGPT2Config\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m         \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGPT2LMHeadModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m         \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_weight\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/vika/cqas_flask/generation/gpt-2-Pytorch/GPT2/model.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, config)\u001b[0m\n\u001b[1;32m    192\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mGPT2LMHeadModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mModule\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    193\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 194\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mGPT2LMHeadModel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    195\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransformer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGPT2Model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    196\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlm_head\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGPT2LMHead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransformer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwte\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: super(type, obj): obj must be an instance or subtype of type"
     ]
    }
   ],
   "source": [
    "from text_gen import text_generator_for_out\n",
    "text_generator_for_out(\"The pizza is better than bread.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▎         | 5/200 [00:00<00:04, 42.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The man is better than woman.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:04<00:00, 41.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "qu\n",
      "======================================== SAMPLE 1 ========================================\n",
      "qu2\n",
      "qu3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "' He\\'s better than the other. He\\'s better than the other man. He\\'s better than the other woman.\\n\\n(7)\\n\\n(A)\\n\\n(B)\\n\\n(C)\\n\\n(D)\\n\\n(E)\\n\\n(F)\\n\\n(G)\\n\\n(H)\\n\\n(I)\\n\\n(J)\\n\\n(K)\\n\\n(L)\\n\\n(M)\\n\\n(N)\\n\\n(O)\\n\\n(P)\\n\\n(Q)\\n\\n(R)\\n\\n(S)\\n\\n(T)\\n\\n(U)\\n\\n(V)\\n\\n(W)\\n\\n(X)\\n\\n(Y)<|endoftext|>The Federal Reserve\\'s policy on quantitative easing—which has been described as a \"market-oriented program\"—has been criticized as a \"market-driven policy,\" according to a New York Times reporter.\\n\\nIn a piece that'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.insert(0, \"/home/vika/cqas_flask/generation/gpt-2-Pytorch\")\n",
    "from text_gen import text_generator_for_out\n",
    "text_generator_for_out(\"The man is better than woman.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▎         | 5/200 [00:00<00:04, 42.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The man is better than woman.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:04<00:00, 42.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "qu\n",
      "======================================== SAMPLE 1 ========================================\n",
      "qu2\n",
      "qu3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"\\n\\nIn order to get her out of the house, she must get to the nearest exit. If she does, she is going to be in jail.\\n\\nAnd the most recent of the many possible consequences for this behavior is that the woman's husband will have to pay for her to go, but the woman's husband will do the rest.\\n\\nThe woman is forced to go.\\n\\nThere is no more responsibility for the husband's actions, but there is no more responsibility for the woman's actions.\\n\\nThe man is responsible for her behavior.\\n\\nThe man is responsible for the woman's behavior.\\n\\nThe woman is responsible for the man's actions.\\n\\nAnd the man is responsible for the woman's actions.\\n\\nThe man is responsible for the woman's actions.\\n\\nThe woman is responsible for the man's actions.\\n\\nAnd the man is responsible for the woman's actions.\\n\\nThe woman is responsible for the man's actions\""
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.insert(0, \"/home/vika/cqas_flask/generation/gpt-2-Pytorch\")\n",
    "from text_gen import text_generator_for_out\n",
    "answer_end = text_generator_for_out(\"The man is better than woman.\")\n",
    "answer_end\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[' He is the best. He is better than a woman. He is the man who is better than a man, and the woman who is better than a woman. He is better than a woman. He is the man who is better than a woman. He is the man who is better than a man. He is the man who is better than a woman. He is the man who is better than a woman. He is the man who is better than a man. He is the man who is better than a woman. He is the man who is better than a man. He is the man who is better than a woman. He is the man who is better than a man. He is the man who is better than a woman. He is the man who is better than a woman. He is the man who is better than a man. He is the man who is better than a woman. He is the man who is better than a man. He is the man who is']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answer_end.splitlines()[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\"I don\\'t have to be a woman to be successful in my profession,\" he said. \"I don\\'t even have to be a man to be a successful man.\"In the past, he has said he would have preferred women to be in his position. He has also said he would have preferred women to be in his position.'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "''.join(answer_end.splitlines()[:6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
