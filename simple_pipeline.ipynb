{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os.path\n",
    "import torch\n",
    "\n",
    "PATH_TO_PRETRAINED = '/home/vika/cqas_flask/external_pretrained_models/'\n",
    "MODEL_NAMES = ['bert_simple1.hdf5']\n",
    "\n",
    "def load(checkpoint_fn, gpu=-1):\n",
    "    if not os.path.isfile(PATH_TO_PRETRAINED + checkpoint_fn):\n",
    "        raise ValueError('Can''t find tagger in file \"%s\". Please, run the main script with non-empty \\\n",
    "                         \"--save-best-path\" param to create it.' % checkpoint_fn)\n",
    "    tagger = torch.load(PATH_TO_PRETRAINED + checkpoint_fn)\n",
    "    tagger.gpu = gpu\n",
    "\n",
    "    tagger.word_seq_indexer.gpu = gpu # hotfix\n",
    "    tagger.tag_seq_indexer.gpu = gpu # hotfix\n",
    "    if hasattr(tagger, 'char_embeddings_layer'):# very hot hotfix\n",
    "        tagger.char_embeddings_layer.char_seq_indexer.gpu = gpu # hotfix\n",
    "    tagger.self_ensure_gpu()\n",
    "    return tagger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/vika/cqas_flask\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ls: cannot access '/home/vika/NER_RNN/targer/src/layers': No such file or directory\n"
     ]
    }
   ],
   "source": [
    "! ls /home/vika/NER_RNN/targer/src/layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.3.1\n"
     ]
    }
   ],
   "source": [
    "import torch \n",
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning:  apex was installed without --cpp_ext.  Falling back to Python flatten and unflatten.\n",
      "Warning:  apex was installed without --cuda_ext. Fused syncbn kernels will be unavailable.  Python fallbacks will be used instead.\n",
      "Warning:  apex was installed without --cuda_ext.  FusedAdam will be unavailable.\n",
      "Warning:  apex was installed without --cuda_ext.  FusedLayerNorm will be unavailable.\n",
      "bert_simple1.hdf5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.6/site-packages/torch/serialization.py:493: SourceChangeWarning: source code of class 'src.layers.layer_context_word_embeddings_bert.LayerContextWordEmbeddingsBert' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
      "  warnings.warn(msg, SourceChangeWarning)\n",
      "/home/user/.local/lib/python3.6/site-packages/torch/serialization.py:493: SourceChangeWarning: source code of class 'torch.nn.modules.sparse.Embedding' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
      "  warnings.warn(msg, SourceChangeWarning)\n",
      "/home/user/.local/lib/python3.6/site-packages/torch/serialization.py:493: SourceChangeWarning: source code of class 'torch.nn.modules.dropout.Dropout' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
      "  warnings.warn(msg, SourceChangeWarning)\n",
      "/home/user/.local/lib/python3.6/site-packages/torch/serialization.py:493: SourceChangeWarning: source code of class 'torch.nn.modules.linear.Linear' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
      "  warnings.warn(msg, SourceChangeWarning)\n",
      "/home/user/.local/lib/python3.6/site-packages/torch/serialization.py:493: SourceChangeWarning: source code of class 'torch.nn.modules.activation.Tanh' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
      "  warnings.warn(msg, SourceChangeWarning)\n",
      "/home/user/.local/lib/python3.6/site-packages/torch/serialization.py:493: SourceChangeWarning: source code of class 'torch.nn.modules.rnn.LSTM' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
      "  warnings.warn(msg, SourceChangeWarning)\n",
      "/home/user/.local/lib/python3.6/site-packages/torch/serialization.py:493: SourceChangeWarning: source code of class 'torch.nn.modules.activation.LogSoftmax' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
      "  warnings.warn(msg, SourceChangeWarning)\n",
      "/home/user/.local/lib/python3.6/site-packages/torch/serialization.py:493: SourceChangeWarning: source code of class 'torch.nn.modules.loss.NLLLoss' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
      "  warnings.warn(msg, SourceChangeWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-2\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('/home/vika/targer')\n",
    "from src.factories.factory_tagger import TaggerFactory\n",
    "from src.layers import layer_context_word_embeddings_bert\n",
    "\n",
    "for MODEL_NAME in ['bert_simple1.hdf5']:\n",
    "    print (MODEL_NAME)\n",
    "    model = TaggerFactory.load(PATH_TO_PRETRAINED + MODEL_NAME, -1)\n",
    "    print (model.gpu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_sequence_from_sentence(str_sentences):\n",
    "    return [str_sentence.lower().split() for str_sentence in str_sentences]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = create_sequence_from_sentence(['what is better amazon or itunes', 'who is better mouse or rat', 'what is easier to make bread or pizza', 'what is better for startap python or mathlab', 'what is better memory foam or gel memory foam', 'what is better perl or python', 'what is better cuda or opencl', 'what is better gamecube or ps2', 'what is preferable beer or milk'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/home/vika/NER_RNN/targer')\n",
    "from src.factories.factory_tagger import TaggerFactory\n",
    "\n",
    "def create_sequence_from_sentence(str_sentences):\n",
    "    return [str_sentence.lower().split() for str_sentence in str_sentences]\n",
    "\n",
    "class extractor:\n",
    "    def __init__(self, input_sentence, model_name = 'bert_simple1.hdf5', model_path = '/home/vika/cqas_flask/external_pretrained_models/'):\n",
    "        self.input_str = input_sentence\n",
    "        self.answ = \"UNKNOWN ERROR\"\n",
    "        self.model_name = model_name\n",
    "        self.model_path = model_path\n",
    "        self.first_object = ''\n",
    "        self.second_object = ''\n",
    "        self.predicates = ''\n",
    "        \n",
    "    def get_objects_predicates(self, list_words, list_tags):\n",
    "        obj_list = []\n",
    "        pred_list = []\n",
    "        for ind, elem in enumerate(list_tags):\n",
    "            if elem == 'B-OBJ':\n",
    "                obj_list.append(list_words[ind])\n",
    "            if elem == 'B-PREDFULL':\n",
    "                pred_list.append(list_words[ind])    \n",
    "        return obj_list, pred_list\n",
    "    \n",
    "    def extract_objects_predicates(self, input_sentence):\n",
    "        words = create_sequence_from_sentence([input_sentence])\n",
    "        print (words)\n",
    "        model = TaggerFactory.load(self.model_path + self.model_name, -1)\n",
    "        print (model.gpu)\n",
    "        #model.cuda(device=2)\n",
    "        #model.gpu = 2\n",
    "        tags = model.predict_tags_from_words(words)\n",
    "        print (tags)\n",
    "        objects, predicates = self.get_objects_predicates(words[0], tags[0])\n",
    "        print (objects)\n",
    "        print (predicates)\n",
    "        self.predicates = predicates\n",
    "        if len(objects) >= 2:\n",
    "            self.first_object = objects[0]\n",
    "            self.second_object = objects[1]\n",
    "        else:\n",
    "            print(\"We have %d objects to compare %s\" %(len(objects), objects))\n",
    "            split_sent = words[0]\n",
    "            if 'or' in split_sent:\n",
    "                or_index = split_sent.index('or')\n",
    "                print (\"or split_sent\", or_index)\n",
    "                try:\n",
    "                    obj1 = split_sent[or_index - 1]\n",
    "                    obj2 = split_sent[or_index + 1]\n",
    "                    print (obj1, obj2)\n",
    "                    self.first_object = obj1\n",
    "                    self.second_object = obj2\n",
    "                except:\n",
    "                    self.answ = \"We can't recognize two objects for compare\" \n",
    "            elif 'vs' in split_sent:\n",
    "                or_index = split_sent.index('vs')\n",
    "                try:\n",
    "                    obj1 = split_sent[or_index - 1]\n",
    "                    obj2 = split_sent[or_index + 1]\n",
    "                    print (obj1, obj2)\n",
    "                    self.first_object = obj1\n",
    "                    self.second_object = obj2\n",
    "                except:\n",
    "                    self.answ = \"We can't recognize two objects for compare\" \n",
    "            else:\n",
    "                self.answ = \"We can't recognize two objects for compare\" \n",
    "    def get_params(self):\n",
    "        self.extract_objects_predicates(self.input_str)\n",
    "        return self.first_object, self.second_object, self.predicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['what', 'is', 'testier', 'bread', 'or', 'pizza']]\n",
      "-2\n",
      "[['O', 'O', 'B-PREDFULL', 'B-OBJ', 'O', 'O']]\n",
      "['bread']\n",
      "['testier']\n",
      "We have 1 objects to compare ['bread']\n",
      "or split_sent 4\n",
      "bread pizza\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('bread', 'pizza', ['testier'])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_extractor = extractor(\"what is testier bread or pizza\")\n",
    "my_extractor.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import requests\n",
    "\n",
    "URL = 'http://ltdemos.informatik.uni-hamburg.de/cam-api'\n",
    "\n",
    "proxies = {\n",
    "  \"http\": \"http://185.46.212.97:10015/\",\n",
    "  \"https\": \"https://185.46.212.98:10015/\",\n",
    "}\n",
    "\n",
    "def get_response(first_object, second_object, fast_search=True, \n",
    "               aspects=None, weights=None):\n",
    "    num_aspects = len(aspects) if aspects is not None else 0\n",
    "    num_weights = len(weights) if weights is not None else 0\n",
    "    if num_aspects != num_weights:\n",
    "        raise ValueError(\n",
    "            \"Number of weights should be equal to the number of aspects\")\n",
    "    params = {\n",
    "        'objectA': first_object,\n",
    "        'objectB': second_object,\n",
    "        'fs': str(fast_search).lower()\n",
    "    }\n",
    "    if num_aspects:\n",
    "        params.update({'aspect{}'.format(i + 1): aspect \n",
    "                       for i, aspect in enumerate(aspects)})\n",
    "        params.update({'weight{}'.format(i + 1): weight \n",
    "                       for i, weight in enumerate(weights)})\n",
    "    print (\"get url\")\n",
    "    response = requests.get(url=URL, params=params, proxies=proxies)\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "class responser:\n",
    "    def __init__(self):\n",
    "        self.URL = 'http://ltdemos.informatik.uni-hamburg.de/cam-api'\n",
    "        self.proxies = {\"http\": \"http://185.46.212.97:10015/\",\"https\": \"https://185.46.212.98:10015/\",}\n",
    "        \n",
    "    def get_response(self, first_object, second_object, fast_search=True, \n",
    "               aspects=None, weights=None):\n",
    "        print (\"aspects\", aspects)\n",
    "        print (\"weights\", weights)\n",
    "        num_aspects = len(aspects) if aspects is not None else 0\n",
    "        num_weights = len(weights) if weights is not None else 0\n",
    "        if num_aspects != num_weights:\n",
    "            raise ValueError(\n",
    "                \"Number of weights should be equal to the number of aspects\")\n",
    "        params = {\n",
    "            'objectA': first_object,\n",
    "            'objectB': second_object,\n",
    "            'fs': str(fast_search).lower()\n",
    "        }\n",
    "        if num_aspects:\n",
    "            params.update({'aspect{}'.format(i + 1): aspect \n",
    "                           for i, aspect in enumerate(aspects)})\n",
    "            params.update({'weight{}'.format(i + 1): weight \n",
    "                           for i, weight in enumerate(weights)})\n",
    "        print (\"get url\")\n",
    "        response = requests.get(url=URL, params=params, proxies=proxies)\n",
    "        return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "URL = 'http://ltdemos.informatik.uni-hamburg.de/cam-api'\n",
    "proxies = {\"http\": \"http://185.46.212.97:10015/\",\"https\": \"https://185.46.212.98:10015/\",}\n",
    "params = {\n",
    "            'objectA': 'cat',\n",
    "            'objectB': 'dog',\n",
    "            'fs': str(True).lower()}\n",
    "response = requests.get(url=URL, params=params, proxies=proxies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 1., 1., 1., 1.])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.ones(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['what', 'is', 'testier', 'bread', 'or', 'pizza']]\n",
      "-2\n",
      "[['O', 'O', 'B-PREDFULL', 'B-OBJ', 'O', 'O']]\n",
      "['bread']\n",
      "['testier']\n",
      "We have 1 objects to compare ['bread']\n",
      "or split_sent 4\n",
      "bread pizza\n",
      "bread pizza ['testier']\n",
      "aspects ['testier']\n",
      "weights [1]\n",
      "get url\n"
     ]
    }
   ],
   "source": [
    "my_responser = responser()\n",
    "obj1, obj2, predicates = my_extractor.get_params()\n",
    "print (obj1, obj2, predicates)\n",
    "if (len(obj1) > 0 and len(obj2) > 0):\n",
    "    response = my_responser.get_response(first_object = obj1, second_object = obj2, fast_search=True, aspects = predicates, weights = [1 for predicate in predicates])\n",
    "else:\n",
    "    print (\"smth wrong with objects obj1 %s obj2 %s\", obj1, obj2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = response.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def answerer(input_string):\n",
    "    my_extractor = extractor(\"what is testier bread or pizza\")\n",
    "    my_responser = responser()\n",
    "    obj1, obj2, predicates = my_extractor.get_params()\n",
    "    print (obj1, obj2, predicates)\n",
    "    if (len(obj1) > 0 and len(obj2) > 0):\n",
    "        response =  my_responser.get_response(first_object = obj1, second_object = obj2, fast_search=True, aspects = predicates, weights = [1 for predicate in predicates])\n",
    "        try:\n",
    "            response_json = response.json()\n",
    "            my_diviner = diviner()\n",
    "            my_diviner.create_from_json(response_json)\n",
    "            answer = my_diviner.generate_advice()\n",
    "            return answer\n",
    "        except:\n",
    "            return (\"smth wrong in response, please try again\")\n",
    "    else:\n",
    "        return (\"smth wrong with objects obj1 %s obj2 %s\", obj1, obj2)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['what', 'is', 'testier', 'bread', 'or', 'pizza']]\n",
      "-2\n",
      "[['O', 'O', 'B-PREDFULL', 'B-OBJ', 'O', 'O']]\n",
      "['bread']\n",
      "['testier']\n",
      "We have 1 objects to compare ['bread']\n",
      "or split_sent 4\n",
      "bread pizza\n",
      "bread pizza ['testier']\n",
      "aspects ['testier']\n",
      "weights [1]\n",
      "get url\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'smth wrong in response, please try again'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answerer(\"what is tastier bread or pizza\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "winnder: pizza  other: bread\n",
      "acpect winner  faster, easier to make, lighter, bigger, simpler, greater, easier to handle, easier, easier to eat\n",
      "acpect other  safer, quicker, easier to find and more expensive, easier for me to make, nicer\n",
      "\n",
      "\n",
      "Pizza is better than bread, because it is faster, easier to make, lighter, bigger, simpler, greater, easier to handle, easier, easier to eat. \n",
      " At the same time, bread is safer, quicker, easier to find and more expensive, easier for me to make, nicer\n"
     ]
    }
   ],
   "source": [
    "from generation.generation import diviner\n",
    "\n",
    "response_json = response.json()\n",
    "Merlin = diviner()\n",
    "Merlin.create_from_json(response_json)\n",
    "Merlin.generate_advice()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['what', 'is', 'testier', 'bread', 'or', 'pizza']]\n",
      "-2\n",
      "[['O', 'O', 'B-PREDFULL', 'B-OBJ', 'O', 'O']]\n",
      "['bread']\n",
      "['testier']\n",
      "We have 1 objects to compare ['bread']\n",
      "sentense [['what', 'is', 'testier', 'bread', 'or', 'pizza']]\n",
      "split sent ['what', 'is', 'testier', 'bread', 'or', 'pizza']\n",
      "have or\n",
      "4\n",
      "obj1 bread\n",
      "obj2 pizza\n",
      "self.first_object bread\n",
      "self.second_object pizza\n",
      "obj1, obj2, predicates bread pizza ['testier']\n",
      "aspects ['testier']\n",
      "weights [1]\n",
      "get url\n",
      "winnder: pizza  other: bread\n",
      "acpect winner  faster, easier to make, lighter, bigger, simpler, greater, easier to handle, easier, easier to eat\n",
      "acpect other  safer, quicker, easier to find and more expensive, easier for me to make, nicer\n",
      "\n",
      "\n",
      "Pizza is better than bread, because it is faster, easier to make, lighter, bigger, simpler, greater, easier to handle, easier, easier to eat. \n",
      " At the same time, bread is safer, quicker, easier to find and more expensive, easier for me to make, nicer\n"
     ]
    }
   ],
   "source": [
    "from my_functions import do_sum, answerer\n",
    "answerer(\"what is better bread o pizza\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
